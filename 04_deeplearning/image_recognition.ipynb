{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "len(Counter(train_Y).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2504d266d40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_X[5], cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "Preprocessing data perlu dilakukan sebelum membuat neural networks supaya data sesuai dengan format input dan output neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = tf.keras.utils.to_categorical(train_Y, num_classes=10)\n",
    "test_label = tf.keras.utils.to_categorical(test_Y, num_classes=10)\n",
    "\n",
    "train_input = tf.data.Dataset.from_tensor_slices((train_X, train_label)).batch(100) # 100 samples diklasifikasi menjadi satu group\n",
    "test_input = tf.data.Dataset.from_tensor_slices((test_X, test_label)).batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,810\n",
      "Trainable params: 109,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(28, 28))\n",
    "dense = tf.keras.layers.Flatten()(input_data)\n",
    "\n",
    "dense = tf.keras.layers.Dense(100, activation='relu')(dense)\n",
    "dense = tf.keras.layers.Dense(100, activation='relu')(dense)\n",
    "dense = tf.keras.layers.Dense(100, activation='relu')(dense)\n",
    "dense = tf.keras.layers.Dense(100, activation='relu')(dense)\n",
    "\n",
    "output_data = tf.keras.layers.Dense(10, activation='softmax')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output_data)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 4s 4ms/step - loss: 1.4097 - accuracy: 0.7385\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.5252 - accuracy: 0.8164\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.4550 - accuracy: 0.8368\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.4213 - accuracy: 0.8479\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.4027 - accuracy: 0.8548\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3803 - accuracy: 0.8606\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3689 - accuracy: 0.8659\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3570 - accuracy: 0.8693\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3485 - accuracy: 0.8724\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3395 - accuracy: 0.8756\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3281 - accuracy: 0.8783\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3234 - accuracy: 0.8816\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3173 - accuracy: 0.8831\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3119 - accuracy: 0.8849\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3048 - accuracy: 0.8878\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2962 - accuracy: 0.8898\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2927 - accuracy: 0.8910\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2880 - accuracy: 0.8924\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2869 - accuracy: 0.8924\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2504d265e40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(train_input, epochs=20) # 20x training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membuat CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 30)        780       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 30)        22530     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 30)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 30)        22530     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5880)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                58810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,650\n",
      "Trainable params: 104,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.expand_dims(train_X, axis=-1)\n",
    "test_data = tf.expand_dims(test_X, axis=-1)\n",
    "\n",
    "# stitching & small-batch processing\n",
    "train_input = tf.data.Dataset.from_tensor_slices((train_data, train_label)).batch(100)\n",
    "test_input = tf.data.Dataset.from_tensor_slices((test_data, test_label)).batch(100)\n",
    "\n",
    "# input layer\n",
    "# CNN input membutuhkan multidimensional channel warna untuk menampilkan image\n",
    "# jika tdk ada dimensi yang ditambahkan, maka akan error\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "# convolutional layer\n",
    "conv = tf.keras.layers.Conv2D(30, 5, padding='SAME', activation='relu')(input_data)\n",
    "conv = tf.keras.layers.Conv2D(30, 5, padding='SAME', activation='relu')(conv)\n",
    "\n",
    "# pooling layer\n",
    "conv = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv)\n",
    "conv = tf.keras.layers.Conv2D(30, 5, padding='SAME', activation='relu')(conv)\n",
    "\n",
    "# buat fully-connected layer\n",
    "dense = tf.keras.layers.Flatten()(conv)\n",
    "output_data = tf.keras.layers.Dense(10, activation='softmax')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output_data)\n",
    "model.compile(optimizer=tf.optimizers.Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 235s 388ms/step - loss: 0.5946 - accuracy: 0.8408\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.3551 - accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3550531268119812, 0.8716999888420105]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test model\n",
    "model.fit(train_input, epochs=1)\n",
    "model.evaluate(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = tf.keras.models.load_model('./model.h5')\n",
    "modelx.evaluate(test_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "661c9fc443e9071e90d7dc80d4092ed007e1e67e17e12b1f6b1cd12c13d9aa66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
