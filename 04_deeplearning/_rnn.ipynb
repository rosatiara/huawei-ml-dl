{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights dari RNN\n",
    "Recurrent Neural Network (RNN) adalah salah satu tipe artificial neural network yang menggunakan data sekuensial atau time series.\n",
    "\n",
    "RNN biasa digunakan untuk masalah yang berkaitan dengan urutan data, seperti language translation, natural language processing (NLP), dan speech recognition. Teknologi terkenal yang menggunakan RNN adalah Siri, Google Translate, Google Assistant, dan lain-lain.\n",
    "\n",
    "Pada RNN, output dari step sebelumnya dijadikan input untuk step sekarang. Fitur terpenting dari RNN adalah **hidden state**, yaitu keadaan saat RNN mengingat informasi tentang urutan yang akan diteliti.\n",
    "\n",
    "RNN dapat dibayangkan seperti serial network yang terhubung. Hubungan mereka bermacam-macam, ada **one-to-one, one-to-many, many-to-one, dan many-to-many.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "step = 3\n",
    "embed_size = 128\n",
    "hidden_size = 128\n",
    "batch_zise = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82886\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, diversity=1.0):\n",
    "      preds = np.asarray(preds).astype('float64')\n",
    "      preds = np.log(preds + 1e-10) / diversity\n",
    "      exp_preds = np.exp(preds)\n",
    "      preds = exp_preds / np.sum(exp_preds)\n",
    "      probas = np.random.multinomial(1, preds, 1)\n",
    "      return np.argmax(probas)\n",
    "\n",
    "def preprocess(source_file):\n",
    "      sentences = []\n",
    "      with open(source_file, 'r', encoding='utf-8') as fr:\n",
    "            lines = fr.readlines()\n",
    "            for line in lines:\n",
    "                  line = line.strip()\n",
    "                  count = 0\n",
    "                  for c in line:\n",
    "                        if (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z'):\n",
    "                              count += 1\n",
    "                        if count/len(line) < 0.1:\n",
    "                              sentences.append(line)\n",
    "      return sentences\n",
    "\n",
    "sentences = preprocess('./lyrics.txt')\n",
    "print(len(sentences))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_map():\n",
    "      chars = {}\n",
    "      for sentence in sentences:\n",
    "            for c in sentence:\n",
    "                  chars[c] = chars.get(c, 0) + 1\n",
    "      chars = sorted(chars.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "      chars = [char[0] for char in chars]\n",
    "      vocab_size = len(chars)\n",
    "\n",
    "      char2id = {c: i for i, c in enumerate(chars)}\n",
    "      id2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "      with open('char2id.pkl', 'wb') as fw:\n",
    "            pickle.dump(char2id, fw)\n",
    "            return char2id, id2char, vocab_size\n",
    "char2id, id2char, vocab_size = bi_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "      index = random.randint(0, len(sentences))\n",
    "      for diversity in [0.2, 0.5, 1.0]:\n",
    "            print('----- diversity:', diversity)\n",
    "            sentence = sentences[index][:maxlen]\n",
    "            print('----- Generating with seed: ' + sentence)\n",
    "            sys.stdout.write(sentence)\n",
    "            for i in range(400):\n",
    "                  x_pred = np.zeros((1, maxlen))\n",
    "                  for t, char in enumerate(sentence):\n",
    "                        x_pred[0, t] = char2id[char]\n",
    "                  preds = model.predict(x_pred, verbose=0)[0]\n",
    "                  next_index = sample(preds, diversity)\n",
    "                  next_char = id2char[next_index]\n",
    "                  sentence = sentence[1:] + next_char\n",
    "def training_data_labels():\n",
    "      X_data = []\n",
    "      Y_data = []\n",
    "      for sentence in sentences:\n",
    "            for i in range(0, len(sentence) - maxlen, step):\n",
    "                  X_data.append([char2id[c] for c in sentence[i: i + maxlen]])\n",
    "                  y = np.zeros(vocab_size, dtype=np.bool)\n",
    "                  y[char2id[sentence[i + maxlen]]] = 1\n",
    "                  Y_data.append(y)\n",
    "      X_data = np.array(X_data)\n",
    "      Y_data = np.array(Y_data)\n",
    "      X_data = X_data[:2000]\n",
    "      Y_data = Y_data[:2000]\n",
    "      return X_data, Y_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 128)           13184     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 103)               13287     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158,055\n",
      "Trainable params: 158,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosat\\AppData\\Local\\Temp\\ipykernel_14720\\1873834691.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros(vocab_size, dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 3.8878----- diversity: 0.2\n",
      "----- Generating with seed: Yeah, I st\n",
      "Yeah, I st----- diversity: 0.5\n",
      "----- Generating with seed: Yeah, I st\n",
      "Yeah, I st----- diversity: 1.0\n",
      "----- Generating with seed: Yeah, I st\n",
      "32/32 [==============================] - 82s 3s/step - loss: 3.8575\n",
      "Epoch 2/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.9834----- diversity: 0.2\n",
      "----- Generating with seed: Oh, oh, oh\n",
      "Oh, oh, oh----- diversity: 0.5\n",
      "----- Generating with seed: Oh, oh, oh\n",
      "Oh, oh, oh----- diversity: 1.0\n",
      "----- Generating with seed: Oh, oh, oh\n",
      "32/32 [==============================] - 104s 3s/step - loss: 2.9833\n",
      "Epoch 3/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 2.9189----- diversity: 0.2\n",
      "----- Generating with seed: You got a \n",
      "You got a ----- diversity: 0.5\n",
      "----- Generating with seed: You got a \n",
      "You got a ----- diversity: 1.0\n",
      "----- Generating with seed: You got a \n",
      "32/32 [==============================] - 88s 3s/step - loss: 2.9225\n",
      "Epoch 4/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 2.8492----- diversity: 0.2\n",
      "----- Generating with seed: We them bo\n",
      "We them bo----- diversity: 0.5\n",
      "----- Generating with seed: We them bo\n",
      "We them bo----- diversity: 1.0\n",
      "----- Generating with seed: We them bo\n",
      "32/32 [==============================] - 102s 3s/step - loss: 2.8476\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.7264----- diversity: 0.2\n",
      "----- Generating with seed: I really h\n",
      "I really h----- diversity: 0.5\n",
      "----- Generating with seed: I really h\n",
      "I really h----- diversity: 1.0\n",
      "----- Generating with seed: I really h\n",
      "32/32 [==============================] - 88s 3s/step - loss: 2.7264\n",
      "Epoch 6/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.5768----- diversity: 0.2\n",
      "----- Generating with seed: She said s\n",
      "She said s----- diversity: 0.5\n",
      "----- Generating with seed: She said s\n",
      "She said s----- diversity: 1.0\n",
      "----- Generating with seed: She said s\n",
      "32/32 [==============================] - 102s 3s/step - loss: 2.5753\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.4241----- diversity: 0.2\n",
      "----- Generating with seed: [Spoken Ou\n",
      "[Spoken Ou----- diversity: 0.5\n",
      "----- Generating with seed: [Spoken Ou\n",
      "[Spoken Ou----- diversity: 1.0\n",
      "----- Generating with seed: [Spoken Ou\n",
      "32/32 [==============================] - 128s 4s/step - loss: 2.4241\n",
      "Epoch 8/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 2.3025----- diversity: 0.2\n",
      "----- Generating with seed: But how 'b\n",
      "But how 'b----- diversity: 0.5\n",
      "----- Generating with seed: But how 'b\n",
      "But how 'b----- diversity: 1.0\n",
      "----- Generating with seed: But how 'b\n",
      "32/32 [==============================] - 152s 5s/step - loss: 2.2919\n",
      "Epoch 9/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.1679----- diversity: 0.2\n",
      "----- Generating with seed: I need to \n",
      "I need to ----- diversity: 0.5\n",
      "----- Generating with seed: I need to \n",
      "I need to ----- diversity: 1.0\n",
      "----- Generating with seed: I need to \n",
      "32/32 [==============================] - 170s 5s/step - loss: 2.1640\n",
      "Epoch 10/10\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.0467----- diversity: 0.2\n",
      "----- Generating with seed: Lot of peo\n",
      "Lot of peo----- diversity: 0.5\n",
      "----- Generating with seed: Lot of peo\n",
      "Lot of peo----- diversity: 1.0\n",
      "----- Generating with seed: Lot of peo\n",
      "32/32 [==============================] - 150s 5s/step - loss: 2.0439\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_size, input_length=maxlen))\n",
    "model.add(LSTM(hidden_size, input_shape=(maxlen, embed_size)))\n",
    "\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "X_data, Y_data = training_data_labels()\n",
    "model.fit(X_data, Y_data, batch_size=batch_zise, epochs=epochs, callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])\n",
    "\n",
    "model.save('./model/song_tf.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & membuat lirik baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\00 Kuliah\\5\\AI 1\\01 After Mid\\huawei-deeplearning\\04_deeplearning\\_rnn.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/00%20Kuliah/5/AI%201/01%20After%20Mid/huawei-deeplearning/04_deeplearning/_rnn.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39m./model/song_tf.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/00%20Kuliah/5/AI%201/01%20After%20Mid/huawei-deeplearning/04_deeplearning/_rnn.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./char2id.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fr:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/00%20Kuliah/5/AI%201/01%20After%20Mid/huawei-deeplearning/04_deeplearning/_rnn.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m       [char2id, id2char] \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(fr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/00%20Kuliah/5/AI%201/01%20After%20Mid/huawei-deeplearning/04_deeplearning/_rnn.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample\u001b[39m(preds, diversity \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/00%20Kuliah/5/AI%201/01%20After%20Mid/huawei-deeplearning/04_deeplearning/_rnn.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m       preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(preds)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "maxlen = 10\n",
    "model = load_model('./model/song_tf.h5')\n",
    "\n",
    "with open('./char2id.pkl', 'rb') as fr:\n",
    "      [char2id, id2char] = pickle.load(fr)\n",
    "\n",
    "def sample(preds, diversity = 1.0):\n",
    "      preds = np.asarray(preds).astype('float64')\n",
    "      preds = np.log(preds + 1e-10) / diversity\n",
    "      exp_preds = np.exp(preds)\n",
    "      preds = exp_preds / np.sum(exp_preds)\n",
    "      probas = np.random.multinomial(1, preds, 1)\n",
    "      return np.argmax(probas)\n",
    "\n",
    "sentence = \"Enter new lyrics: \"\n",
    "sentence = sentence[:maxlen]\n",
    "\n",
    "diversity = 1.0\n",
    "print('----- generating with seed: ' + sentence)\n",
    "print('----- diversity:', diversity)\n",
    "sys.stdout.write(sentence)\n",
    "\n",
    "for i in range(40):\n",
    "      x_pred = np.zeros((1, maxlen))\n",
    "      for t, char in enumerate(sentence):\n",
    "            x_pred[0, t] = char2id[char]\n",
    "      \n",
    "      preds = model.predict(x_pred, verbose=0)[0]\n",
    "      next_index = sample(preds, diversity)\n",
    "      next_char = id2char[next_index]\n",
    "\n",
    "      sentence = sentence[1:] + next_char\n",
    "      sys.stdout.write(next_char)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "661c9fc443e9071e90d7dc80d4092ed007e1e67e17e12b1f6b1cd12c13d9aa66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
