{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights dari RNN\n",
    "Recurrent Neural Network (RNN) adalah salah satu tipe artificial neural network yang menggunakan data sekuensial atau time series.\n",
    "\n",
    "RNN biasa digunakan untuk masalah yang berkaitan dengan urutan data, seperti language translation, natural language processing (NLP), dan speech recognition. Teknologi terkenal yang menggunakan RNN adalah Siri, Google Translate, Google Assistant, dan lain-lain.\n",
    "\n",
    "Pada RNN, output dari step sebelumnya dijadikan input untuk step sekarang. Fitur terpenting dari RNN adalah **hidden state**, yaitu keadaan saat RNN mengingat informasi tentang urutan yang akan diteliti.\n",
    "\n",
    "RNN dapat dibayangkan seperti serial network yang terhubung. Hubungan mereka bermacam-macam, ada **one-to-one, one-to-many, many-to-one, dan many-to-many.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "step = 3\n",
    "embed_size = 128\n",
    "hidden_size = 128\n",
    "batch_zise = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82886\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, diversity=1.0):\n",
    "      preds = np.asarray(preds).astype('float64')\n",
    "      preds = np.log(preds + 1e-10) / diversity\n",
    "      exp_preds = np.exp(preds)\n",
    "      preds = exp_preds / np.sum(exp_preds)\n",
    "      probas = np.random.multinomial(1, preds, 1)\n",
    "      return np.argmax(probas)\n",
    "\n",
    "def preprocess(source_file):\n",
    "      sentences = []\n",
    "      with open(source_file, 'r', encoding='utf-8') as fr:\n",
    "            lines = fr.readlines()\n",
    "            for line in lines:\n",
    "                  line = line.strip()\n",
    "                  count = 0\n",
    "                  for c in line:\n",
    "                        if (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z'):\n",
    "                              count += 1\n",
    "                        if count/len(line) < 0.1:\n",
    "                              sentences.append(line)\n",
    "      return sentences\n",
    "\n",
    "sentences = preprocess('./lyrics.txt')\n",
    "print(len(sentences))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_map():\n",
    "      chars = {}\n",
    "      for sentence in sentences:\n",
    "            for c in sentence:\n",
    "                  chars[c] = chars.get(c, 0) + 1\n",
    "      chars = sorted(chars.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "      chars = [char[0] for char in chars]\n",
    "      vocab_size = len(chars)\n",
    "\n",
    "      char2id = {c: i for i, c in enumerate(chars)}\n",
    "      id2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "      with open('char2id.pkl', 'wb') as fw:\n",
    "            pickle.dump(char2id, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "      index = random.randint(0, len(sentences))\n",
    "      for diversity in [0.2, 0.5, 1.0]:\n",
    "            print('----- diversity:', diversity)\n",
    "            sentence = sentences[index][:maxlen]\n",
    "            print('----- Generating with seed: ' + sentence)\n",
    "            sys.stdout.write(sentence)\n",
    "            for i in range(400):\n",
    "                  x_pred = np.zeros((1, maxlen))\n",
    "                  for t, char in enumerate(sentence):\n",
    "                        x_pred[0, t] = char2id[char]\n",
    "                  preds = model.predict(x_pred, verbose=0)[0]\n",
    "                  next_index = sample(preds, diversity)\n",
    "                  next_char = id2char[next_index]\n",
    "                  sentence = sentence[1:] + next_char\n",
    "def training_data_labels():\n",
    "      X_data = []\n",
    "      Y_data = []\n",
    "      for sentence in sentences:\n",
    "            for i in range(0, len(sentence) - maxlen, step):\n",
    "                  X_data.append([char2id[c] for c in sentence[i: i + maxlen]])\n",
    "                  y = np.zeros(vocab_size, dtype=np.bool)\n",
    "                  y[char2id[sentence[i + maxlen]]] = 1\n",
    "                  Y_data.append(y)\n",
    "      X_data = np.array(X_data)\n",
    "      Y_data = np.array(Y_data)\n",
    "      X_data = X_data[:2000]\n",
    "      Y_data = Y_data[:2000]\n",
    "      return X_data, Y_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_size, input_length=maxlen))\n",
    "model.add(LSTM(hidden_size, input_shape=(maxlen, embed_size)))\n",
    "\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "X_data, Y_data = training_data_labels()\n",
    "model.fit(X_data, Y_data, batch_size=batch_zise, epochs=epochs, callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])\n",
    "\n",
    "model.save('./model/song_tf.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & membuat lirik baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "maxlen = 10\n",
    "model = load_model('./model/song_tf.h5')\n",
    "\n",
    "with open('./char2id.pkl', 'rb') as fr:\n",
    "      [char2id, id2char] = pickle.load(fr)\n",
    "\n",
    "def sample(preds, diversity = 1.0):\n",
    "      preds = np.asarray(preds).astype('float64')\n",
    "      preds = np.log(preds + 1e-10) / diversity\n",
    "      exp_preds = np.exp(preds)\n",
    "      preds = exp_preds / np.sum(exp_preds)\n",
    "      probas = np.random.multinomial(1, preds, 1)\n",
    "      return np.argmax(probas)\n",
    "\n",
    "sentence = \"Enter new lyrics: \"\n",
    "sentence = sentence[:maxlen]\n",
    "\n",
    "diversity = 1.0\n",
    "print('----- generating with seed: ' + sentence)\n",
    "print('----- diversity:', diversity)\n",
    "sys.stdout.write(sentence)\n",
    "\n",
    "for i in range(40):\n",
    "      x_pred = np.zeros((1, maxlen))\n",
    "      for t, char in enumerate(sentence):\n",
    "            x_pred[0, t] = char2id[char]\n",
    "      \n",
    "      preds = model.predict(x_pred, verbose=0)[0]\n",
    "      next_index = sample(preds, diversity)\n",
    "      next_char = id2char[next_index]\n",
    "\n",
    "      sentence = sentence[1:] + next_char\n",
    "      sys.stdout.write(next_char)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "661c9fc443e9071e90d7dc80d4092ed007e1e67e17e12b1f6b1cd12c13d9aa66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
